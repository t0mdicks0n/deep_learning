{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52a0da50-d1bb-4e1b-bd16-2d859c8db629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM (Longer Run)...\n",
      "Iteration 5000, Avg Loss: 0.6647\n",
      "Iteration 10000, Avg Loss: 0.4870\n",
      "Iteration 15000, Avg Loss: 0.2589\n",
      "Iteration 20000, Avg Loss: 0.1178\n",
      "Iteration 25000, Avg Loss: 0.0405\n",
      "Training finished!\n",
      "\n",
      "--- TEST RESULTS ---\n",
      "\n",
      "--- THE FINAL EXAM (Names NEVER seen before) ---\n",
      "Name: Gunnar     -> Prediction: Boy (98.9%)\n",
      "Name: Annika     -> Prediction: Girl (99.5%)\n",
      "Name: Torbjörn   -> Prediction: Boy (99.8%)\n",
      "Name: Åsa        -> Prediction: Girl (98.2%)\n",
      "Name: Kjell      -> Prediction: Boy (100.0%)\n",
      "Name: Olle       -> Prediction: Boy (99.6%)\n",
      "Name: Louise     -> Prediction: Girl (98.5%)\n",
      "Name: Nisse      -> Prediction: Boy (98.5%)\n",
      "Name: Lasse      -> Prediction: Boy (99.8%)\n",
      "Name: Therese    -> Prediction: Girl (96.4%)\n",
      "Name: Sixten     -> Prediction: Boy (97.7%)\n",
      "Name: Ellen      -> Prediction: Boy (89.6%)\n",
      "Name: Hjalmar    -> Prediction: Boy (99.8%)\n",
      "Name: Ebba       -> Prediction: Girl (100.0%)\n",
      "Name: Love       -> Prediction: Boy (97.8%)\n",
      "Name: Signe      -> Prediction: Girl (99.3%)\n",
      "Name: Melker     -> Prediction: Boy (100.0%)\n",
      "Name: Astrid     -> Prediction: Girl (65.7%)\n",
      "Name: Pontus     -> Prediction: Boy (100.0%)\n",
      "Name: Malte      -> Prediction: Boy (97.8%)\n",
      "\n",
      "--- TEST RESULTS (Unseen Names) ---\n",
      "Name: Gunnar     -> Prediction: Boy (98.9%)\n",
      "Name: Annika     -> Prediction: Girl (99.5%)\n",
      "Name: Torbjörn   -> Prediction: Boy (99.8%)\n",
      "Name: Åsa        -> Prediction: Girl (98.2%)\n",
      "Name: Kjell      -> Prediction: Boy (100.0%)\n",
      "Name: Olle       -> Prediction: Boy (99.6%)\n",
      "Name: Louise     -> Prediction: Girl (98.5%)\n",
      "Name: Nisse      -> Prediction: Boy (98.5%)\n",
      "Name: Lasse      -> Prediction: Boy (99.8%)\n",
      "Name: Peter      -> Prediction: Boy (100.0%)\n",
      "Name: Lollo      -> Prediction: Boy (96.7%)\n",
      "Name: Kalle      -> Prediction: Boy (99.2%)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# --- 1. PREPARATION: The Vocabulary ---\n",
    "# We need to map every letter to a unique number.\n",
    "# We include a generic set of characters (a-z) and a few extras.\n",
    "all_letters = \"abcdefghijklmnopqrstuvwxyzåäöABCDEFGHIJKLMNOPQRSTUVWXYZÅÄÖ .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "def name_to_tensor(name):\n",
    "    \"\"\"\n",
    "    Converts a string \"Anna\" into a Tensor of shape (Length, 1, n_letters).\n",
    "    We use 'One-Hot Encoding': A vector of zeros with a single '1' at the letter's index.\n",
    "    \"\"\"\n",
    "    tensor = torch.zeros(len(name), 1, n_letters)\n",
    "    for li, letter in enumerate(name):\n",
    "        # Find the index of the letter in our list\n",
    "        try:\n",
    "            index = all_letters.index(letter)\n",
    "            tensor[li][0][index] = 1\n",
    "        except ValueError:\n",
    "            continue # Ignore weird characters\n",
    "    return tensor\n",
    "\n",
    "# --- 2. SWEDISH DATASET ---\n",
    "# 0 = Boy (Pojke), 1 = Girl (Flicka)\n",
    "training_data = [\n",
    "    # --- POJKAR (Boys) ---\n",
    "    # The \"Names ending in E\" (Nicknames)\n",
    "    (\"Lasse\", 0), (\"Bosse\", 0), (\"Nisse\", 0), (\"Olle\", 0), (\"Hasse\", 0),\n",
    "    (\"Janne\", 0), (\"Roffe\", 0), (\"Kalle\", 0), (\"Pelle\", 0), (\"Sune\", 0),\n",
    "    (\"Åke\", 0), (\"Börje\", 0), (\"Arne\", 0), (\"Svante\", 0), (\"Christer\", 0),\n",
    "    \n",
    "    # Classic Swedish\n",
    "    (\"Gunnar\", 0), (\"Anders\", 0), (\"Johan\", 0), (\"Lars\", 0), (\"Mikael\", 0),\n",
    "    (\"Per\", 0), (\"Karl\", 0), (\"Hans\", 0), (\"Peter\", 0), (\"Jan\", 0),\n",
    "    (\"Thomas\", 0), (\"Erik\", 0), (\"Fredrik\", 0), (\"Bengt\", 0), (\"Sven\", 0),\n",
    "    (\"Magnus\", 0), (\"Gustav\", 0), (\"Oscar\", 0), (\"William\", 0), (\"Lucas\", 0),\n",
    "    (\"Alexander\", 0), (\"Björn\", 0), (\"Ulf\", 0), (\"Göran\", 0), (\"Stefan\", 0),\n",
    "    (\"Mats\", 0), (\"Leif\", 0), (\"Marcus\", 0), (\"Torbjörn\", 0), (\"Kjell\", 0),\n",
    "    (\"Håkan\", 0), (\"Lennart\", 0), (\"Stig\", 0), (\"Kerstin\", 0), (\"Olof\", 0),\n",
    "    (\"Rolf\", 0), (\"Tommy\", 0), (\"Ingvar\", 0), (\"Kenneth\", 0), (\"Jörgen\", 0),\n",
    "\n",
    "    # --- FLICKOR (Girls) ---\n",
    "    # The \"Confusing E endings\"\n",
    "    (\"Marie\", 1), (\"Therese\", 1), (\"Louise\", 1), (\"Sofie\", 1), (\"Emelie\", 1),\n",
    "    (\"Natalie\", 1), (\"Alice\", 1), (\"Tove\", 1), (\"Signe\", 1), (\"Beatrice\", 1),\n",
    "    (\"Irene\", 1), (\"Caroline\", 1), (\"Madeleine\", 1), (\"Amelie\", 1), (\"Elin\", 1),\n",
    "    \n",
    "    # Classic Swedish\n",
    "    (\"Anna\", 1), (\"Eva\", 1), (\"Maria\", 1), (\"Karin\", 1), (\"Kristina\", 1),\n",
    "    (\"Lena\", 1), (\"Sara\", 1), (\"Malin\", 1), (\"Emma\", 1), (\"Ingrid\", 1),\n",
    "    (\"Birgitta\", 1), (\"Marianne\", 1), (\"Jenny\", 1), (\"Maja\", 1), (\"Elsa\", 1),\n",
    "    (\"Julia\", 1), (\"Linnea\", 1), (\"Wilma\", 1), (\"Ebba\", 1), (\"Ida\", 1),\n",
    "    (\"Saga\", 1), (\"Klara\", 1), (\"Ulla\", 1), (\"Elisabeth\", 1), (\"Monica\", 1),\n",
    "    (\"Hanna\", 1), (\"Linda\", 1), (\"Susanne\", 1), (\"Agneta\", 1), (\"Katarina\", 1),\n",
    "    (\"Gunilla\", 1), (\"Annika\", 1), (\"Britt\", 1), (\"Inger\", 1), (\"Åsa\", 1),\n",
    "    (\"Siv\", 1), (\"Barbro\", 1), (\"Lisbet\", 1), (\"Maj\", 1), (\"Anita\", 1)\n",
    "]\n",
    "\n",
    "# --- 3. THE MODEL (RNN) ---\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # LSTM replaces RNN\n",
    "        # It's smarter at keeping context over long sequences\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        # LSTM needs TWO hidden states: \n",
    "        # 1. h0 (Hidden state - working memory)\n",
    "        # 2. c0 (Cell state - long-term memory)\n",
    "        h0 = torch.zeros(1, 1, self.hidden_size)\n",
    "        c0 = torch.zeros(1, 1, self.hidden_size)\n",
    "        \n",
    "        # LSTM returns: output, (hidden_state, cell_state)\n",
    "        _, (hidden, cell) = self.lstm(input_tensor, (h0, c0))\n",
    "        \n",
    "        # We use the final hidden state for prediction\n",
    "        output = self.fc(hidden[0]) \n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "# --- 4. TRAINING ---\n",
    "# Setup\n",
    "model = LSTM(n_letters, 128, 1) # Keep Hidden size 128\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# INCREASE LEARNING RATE: 0.005 -> 0.01 (Helps get out of the 0.69 plateau)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "print(\"Training LSTM (Longer Run)...\")\n",
    "loss_avg = 0\n",
    "\n",
    "# INCREASE ITERATIONS: 2000 -> 25000\n",
    "# Since we only look at 1 name at a time, we need MANY loops to see the dataset enough times.\n",
    "for epoch in range(25000):\n",
    "    name, label = random.choice(training_data)\n",
    "    \n",
    "    input_tensor = name_to_tensor(name)\n",
    "    target_tensor = torch.tensor([[float(label)]])\n",
    "\n",
    "    output = model(input_tensor)\n",
    "    loss = criterion(output, target_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_avg += loss.item()\n",
    "    \n",
    "    if (epoch+1) % 5000 == 0:\n",
    "        print(f\"Iteration {epoch+1}, Avg Loss: {loss_avg/5000:.4f}\")\n",
    "        loss_avg = 0\n",
    "\n",
    "print(\"Training finished!\")\n",
    "\n",
    "# --- 3. RE-TEST ---\n",
    "print(\"\\n--- TEST RESULTS ---\")\n",
    "test_names = [\"Gunnar\", \"Annika\", \"Torbjörn\", \"Åsa\", \"Kjell\", \"Olle\", \"Louise\", \"Nisse\", \"Lasse\", \"Therese\"]\n",
    "\n",
    "print(\"\\n--- THE FINAL EXAM (Names NEVER seen before) ---\")\n",
    "\n",
    "for name in test_names:\n",
    "    predict(name)\n",
    "\n",
    "# These names are NOT in your training_data list\n",
    "final_exam = [\n",
    "    \"Sixten\",   # Boy (Classic)\n",
    "    \"Ellen\",    # Girl (Classic)\n",
    "    \"Hjalmar\",  # Boy (Old school)\n",
    "    \"Ebba\",     # Girl (Very popular)\n",
    "    \"Love\",     # Boy (The ultimate trick! Ends in e, looks like English 'Love')\n",
    "    \"Signe\",    # Girl (Ends in e)\n",
    "    \"Melker\",   # Boy (Ends in r)\n",
    "    \"Astrid\",   # Girl (Ends in d)\n",
    "    \"Pontus\",   # Boy (Ends in s, but not double s)\n",
    "    \"Malte\"     # Boy (Ends in e, generic structure)\n",
    "]\n",
    "\n",
    "for name in final_exam:\n",
    "    predict(name)\n",
    "\n",
    "# --- 5. TESTING ---\n",
    "def predict(name):\n",
    "    with torch.no_grad():\n",
    "        tensor = name_to_tensor(name)\n",
    "        output = model(tensor)\n",
    "        prob = output.item()\n",
    "        \n",
    "        # If > 0.5 it's a Girl (1), else Boy (0)\n",
    "        guess = \"Girl\" if prob > 0.5 else \"Boy\"\n",
    "        confidence = prob if prob > 0.5 else 1 - prob\n",
    "        print(f\"Name: {name:10} -> Prediction: {guess} ({confidence*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n--- TEST RESULTS (Unseen Names) ---\")\n",
    "predict(\"Gunnar\")   # Boy (Ends in r)\n",
    "predict(\"Annika\")   # Girl (Ends in a)\n",
    "predict(\"Torbjörn\") # Boy (Ends in n)\n",
    "predict(\"Åsa\")      # Girl (Short, ends in a)\n",
    "predict(\"Kjell\")    # Boy (Double consonant)\n",
    "predict(\"Olle\")\n",
    "predict(\"Louise\")\n",
    "predict(\"Nisse\")\n",
    "predict(\"Lasse\")\n",
    "\n",
    "predict(\"Peter\")\n",
    "predict(\"Lollo\")\n",
    "predict(\"Kalle\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51af2f26-9e72-4f00-bed7-1f440b562bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing: Ellen\n",
      "Step 1 ('E'): Boy (67.9%)\n",
      "Step 2 ('El'): Boy (99.0%)\n",
      "Step 3 ('Ell'): Boy (99.8%)\n",
      "Step 4 ('Elle'): Boy (95.7%)\n",
      "Step 5 ('Ellen'): Boy (89.6%)\n",
      "\n",
      "Analyzing: Lollo\n",
      "Step 1 ('L'): Boy (88.4%)\n",
      "Step 2 ('Lo'): Boy (91.4%)\n",
      "Step 3 ('Lol'): Boy (99.9%)\n",
      "Step 4 ('Loll'): Boy (100.0%)\n",
      "Step 5 ('Lollo'): Boy (96.7%)\n"
     ]
    }
   ],
   "source": [
    "def analyze_name(name):\n",
    "    print(f\"\\nAnalyzing: {name}\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_tensor = name_to_tensor(name)\n",
    "        \n",
    "        # We need to manually step through the LSTM to see the hidden state evolve\n",
    "        h0 = torch.zeros(1, 1, 128)\n",
    "        c0 = torch.zeros(1, 1, 128)\n",
    "        hidden = (h0, c0)\n",
    "        \n",
    "        for i in range(len(name)):\n",
    "            # Feed one letter at a time\n",
    "            letter_tensor = input_tensor[i].unsqueeze(0) \n",
    "            _, hidden = model.lstm(letter_tensor, hidden)\n",
    "            \n",
    "            # Predict based on current memory\n",
    "            output = model.fc(hidden[0])\n",
    "            prob = model.sigmoid(output).item()\n",
    "            \n",
    "            # Print the brain's status\n",
    "            guess = \"Girl\" if prob > 0.5 else \"Boy\"\n",
    "            conf = prob if prob > 0.5 else 1 - prob\n",
    "            print(f\"Step {i+1} ('{name[:i+1]}'): {guess} ({conf*100:.1f}%)\")\n",
    "\n",
    "# Run it\n",
    "analyze_name(\"Ellen\")\n",
    "analyze_name(\"Lollo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
